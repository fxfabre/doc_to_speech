{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28766d31-30b9-486b-a04e-3589a2dd4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "\n",
    "from transformers import BarkModel\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "\n",
    "torch.cuda.get_device_name(), torch.cuda.get_device_capability(), torch.cuda.temperature()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc527bc0-a62d-4bb5-90e0-40391bbfec5e",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ebc6f-131e-4eb5-911c-6d5f54b6a10c",
   "metadata": {},
   "source": [
    "## Working, CPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1df4cb6a-1c25-4d01-92da-a8b04bcd44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from transformers import AutoProcessor, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6047ac71-b2d2-42a1-a116-4c4e7a95dae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"suno/bark-small\", cache_dir=\"model\")\n",
    "model = AutoModel.from_pretrained(\"suno/bark-small\", cache_dir=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34151683-3202-4907-b841-df40c5046f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Le petit Prince. Il était une fois un ours blanc qui vivait aux USA\"\n",
    "voice_preset=\"v2/fr_speaker_2\"\n",
    "\n",
    "inputs = processor(\n",
    "    text=[sequence],\n",
    "    voice_preset=voice_preset,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "speech_values = model.generate(\n",
    "    **inputs,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "scipy.io.wavfile.write(\n",
    "    f\"output/bark_\" + voice_preset.split(\"/\").pop() + \".wav\",\n",
    "    rate=model.generation_config.sample_rate,\n",
    "    data=speech_values.cpu().numpy().squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28cf04-403a-462d-a5ba-8242176e3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chown -R 1000:1000 output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3228a62-0241-4d69-8533-90151671d880",
   "metadata": {},
   "source": [
    "## Dev, on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5fc748-bc63-4c57-80d2-2425a16a1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "offload_models = False\n",
    "use_small_models = True\n",
    "os.environ[\"SUNO_OFFLOAD_CPU\"] = str(offload_models)\n",
    "os.environ[\"SUNO_USE_SMALL_MODELS\"] = str(use_small_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2e786e-2e04-42fc-af15-6d9082fe9718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from bark.generation import (\n",
    "    generate_text_semantic,\n",
    "    preload_models,\n",
    "    models,\n",
    ")\n",
    "import bark.generation\n",
    "\n",
    "from bark.api import semantic_to_waveform\n",
    "from bark import generate_audio, SAMPLE_RATE\n",
    "\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b500c9-1c64-4aa9-a805-2e2c0a753f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda mem 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "print(\"Cuda mem\", torch.cuda.memory_allocated())\n",
    "\n",
    "preload_models(\n",
    "    text_use_small=use_small_models,\n",
    "    coarse_use_small=use_small_models,\n",
    "    fine_use_small=use_small_models,\n",
    "    force_reload=True,\n",
    ")\n",
    "print(\"Cuda mem\", torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f47885-62ed-4057-b075-5b8353e9fbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small models True, offloading to CPU: False\n",
      "\tmax memory usage = 2949MB\n"
     ]
    }
   ],
   "source": [
    "audio_array = generate_audio(\n",
    "    \"madam I'm adam\",\n",
    "    history_prompt=\"v2/en_speaker_5\",\n",
    "    silent=True\n",
    ")\n",
    "\n",
    "max_utilization = torch.cuda.max_memory_allocated()\n",
    "print(f\"Small models {use_small_models}, offloading to CPU: {offload_models}\")\n",
    "print(f\"\\tmax memory usage = {max_utilization / 1024 / 1024:.0f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66794a42-9059-4a50-b4a0-ddd5593f3626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "os.makedirs(\"/app/output\", exist_ok=True)\n",
    "scipy.io.wavfile.write(\n",
    "    f\"/app/output/bark_test.wav\",\n",
    "    rate=SAMPLE_RATE,\n",
    "    data=audio_array\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea648ee-06e4-49c4-a982-12715dcede23",
   "metadata": {},
   "source": [
    "# Sample V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639db55-e63e-4dc2-b714-5535b95fd92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import Audio\n",
    "import nltk  # we'll use this to split into sentences\n",
    "import numpy as np\n",
    "\n",
    "from bark.generation import (\n",
    "    generate_text_semantic,\n",
    "    preload_models,\n",
    ")\n",
    "from bark.api import semantic_to_waveform\n",
    "from bark import generate_audio, SAMPLE_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e4131f-32c7-420d-8cfe-7100d9a4c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_TEMP = 0.6\n",
    "SPEAKER = \"v2/fr_speaker_6\"\n",
    "silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
    "\n",
    "pieces = []\n",
    "sentence = \"madam I'm adam\"\n",
    "semantic_tokens = generate_text_semantic(\n",
    "    sentence,\n",
    "    history_prompt=SPEAKER,\n",
    "    temp=GEN_TEMP,\n",
    "    min_eos_p=0.05,  # this controls how likely the generation is to end\n",
    ")\n",
    "\n",
    "audio_array = semantic_to_waveform(semantic_tokens, history_prompt=SPEAKER,)\n",
    "pieces += [audio_array, silence.copy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bad54a-819c-47b8-8e49-e2be36a10fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "749332db-6ea2-4573-bf9b-683f665a4783",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e70cd8-b3ee-4fa5-a4f8-0c318ce86c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = AutoModel.from_pretrained(\"suno/bark-small\", torch_dtype=torch.float16, cache_dir=\"/app/model\")#.to(device)\n",
    "#model.enable_cpu_offload()\n",
    "processor = AutoProcessor.from_pretrained(\"suno/bark-small\", cache_dir=\"/app/model\")\n",
    "\n",
    "voice_preset = \"v2/fr_speaker_2\"\n",
    "sequence = \"Le petit Prince. Il était une fois un ours blanc qui vivait aux USA. Et il s'appelait Poulpe. Original pour un ours !\"\n",
    "\n",
    "inputs = processor(sequence, voice_preset=voice_preset)#.to(device)\n",
    "\n",
    "audio_array = model.generate(**inputs)\n",
    "audio_array = audio_array.cpu().numpy().squeeze()\n",
    "sample_rate = model.generation_config.sample_rate\n",
    "\n",
    "scipy.io.wavfile.write(\"output/bark_generation.wav\", rate=sample_rate, data=audio_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de763b33-ac45-4305-a973-f8d0d3a66324",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config, model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee44a9-75ca-4c53-835d-5c491d0d3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"Le petit Prince. Il était une fois un ours blanc qui vivait aux USA. Et il s'appelait Poulpe. Original pour un ours !\"\n",
    "tokens = processor.tokenizer.tokenize(sequence)\n",
    "encoded = processor.tokenizer.encode(sequence)\n",
    "processor.tokenizer.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79471ca-a8b5-4b9a-bcd9-27469cd51770",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "history_prompt = inputs[\"history_prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cc299-1b5a-4176-b696-9d72f640312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join(\"output\", datetime.utcnow().date().isoformat())\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "sequence = \"Le petit Prince. Il était une fois un ours blanc qui vivait aux USA. Et il s'appelait Poulpe. Original pour un ours !\"\n",
    "attention_masks = [None] * 10\n",
    "history_prompts = [None] * 10\n",
    "\n",
    "for preset in range(0, 1):\n",
    "    print(\"generate preset\", preset)\n",
    "    inputs = processor(\n",
    "        text=sequence,\n",
    "        voice_preset=f\"v2/fr_speaker_{preset}\",\n",
    "        return_tensors=\"pt\",\n",
    "    )#.to(\"cuda\")\n",
    "\n",
    "    print(\"inputs :\", inputs.keys())\n",
    "    #print(\"attention mask :\", len(inputs[\"attention_mask\"]), sum(inputs[\"attention_mask\"]))\n",
    "    \n",
    "    #inputs[\"attention_mask\"] = attention_mask\n",
    "    #inputs[\"history_prompt\"] = history_prompt\n",
    "    \n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    history_prompt = inputs[\"history_prompt\"]\n",
    "\n",
    "    #attention_masks[preset] = inputs[\"attention_mask\"]\n",
    "    #history_prompts[preset] = inputs[\"history_prompt\"]\n",
    "    \n",
    "    speech_values = model.generate(\n",
    "        #attention_mask=attention_mask,\n",
    "        #input_ids=input_ids,\n",
    "        #history_prompt=history_prompt,\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "    )\n",
    "\n",
    "    scipy.io.wavfile.write(\n",
    "        os.path.join(output_folder, f\"bark_fr{preset}.wav\"),\n",
    "        rate=model.generation_config.sample_rate,\n",
    "        data=speech_values.cpu().numpy().squeeze()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54fae2-53bf-406a-80fb-68cbb2232c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chown -R 1000:1000 output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518de16-179f-43ee-b053-5dc374434b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
